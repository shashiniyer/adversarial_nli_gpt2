{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Map-back\n",
    "\n",
    "## Task Description\n",
    "\n",
    "__Given files 1-5 containing GPT2 features (see \"feature_engg\" notebook), map them back to the original datasets__\n",
    "\n",
    "- snli_train_premise: all of file 1; 0 - 250,152 (250,152 records) of file 2\n",
    "- snli_train_hypothesis: from 250,152 in file 2 (49,848 records); all of file 3; 0 - 200,304 (200,304 records) of file 4\n",
    "- snli_valid_premise: 200,304 - 210,304 in file 4 (10,000 records)\n",
    "- snli_valid_hypothesis: 210,304 - 220,304 in file 4 (10,000 records)\n",
    "- snli_test_premise: 220,304 - 230,304 in file 4 (10,000 records)\n",
    "- snli_test_hypothesis: 230,304 - 240,304 in file 4 (10,000 records)\n",
    "- hans_train_premise: 240,304 - 270,304 in file 4 (30,000 records)\n",
    "- hans_train_hypothesis: from 270,304 in file 4 (29,626 records); 0 - 304 of file 5 (304 records)\n",
    "- hans_valid_premise: 304 - 30,304 in file 5 (30,000 records)\n",
    "- hans_valid_hypothesis: 30,304 - 60,304 in file 5 (30,000 records)\n",
    "- nli_diagnostics_premise: 60,304 - 61,408 in file 5 (1,104 records)\n",
    "- nli_diagnostics_hypothesis: 61,408 onwards in file 5\n",
    "\n",
    "__Ultimately, the following datasets are needed:__\n",
    "- snli_train: 550152 obs x 768 features x 2 (hypothesis + premise) - final shape: 550152 x 1536\n",
    "- snli_valid: 10000 obs x 768 features x 2 (hypothesis + premise) - final shape: 10000 x 1536\n",
    "- snli_test: 10000 obs x 768 features x 2 (hypothesis + premise) - final shape: 10000 x 1536\n",
    "- hans (includes train and valid folds): 30000 obs x 768 features x 2 (hypothesis + premise) x 2 (train + valid) - final shape: 60000 x 1536\n",
    "- nli_diagnostics: 1104 obs x 768 features x 2 (hypothesis + premise) - final shape: 1104 x 1536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read files in and perform mapping\n",
    "- Ordering of operations based on availability of resources (memory and disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 55.29924917221069 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "file1 = pd.read_csv('../data/features/out1.csv', header = None)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 59.43683886528015 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "file2 = pd.read_csv('../data/features/out2.csv', header = None)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 60.7894070148468 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "file3 = pd.read_csv('../data/features/out3.csv', header = None)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_train_premise = pd.concat([file1, file2.iloc[0:250152, :]], axis = 0).reset_index(drop=True)\n",
    "del file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 60.93753695487976 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "file4 = pd.read_csv('../data/features/out4.csv', header = None)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_train_hypothesis = pd.concat(\n",
    "    [file2.iloc[250152:, :], file3, file4[0:200304]], axis = 0).reset_index(drop=True)\n",
    "del file2, file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550152, 1536)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli_train = pd.concat([snli_train_premise, snli_train_hypothesis], axis = 1, ignore_index = True)\n",
    "del snli_train_premise, snli_train_hypothesis\n",
    "snli_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_valid = pd.concat([file4[200304:210304].reset_index(drop=True), \n",
    "                        file4[210304:220304].reset_index(drop=True)], axis = 1, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_test = pd.concat([file4[220304:230304].reset_index(drop=True),\n",
    "                       file4[230304:240304].reset_index(drop=True)], axis = 1, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.934419870376587 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "file5 = pd.read_csv('../data/features/out5.csv', header = None)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hans_premise = pd.concat([file4[240304:270304].reset_index(drop=True),\n",
    "                          file5[304:30304].reset_index(drop=True)], axis = 0).reset_index(drop=True)\n",
    "hans_hypothesis = pd.concat([file4[270304:].reset_index(drop=True),\n",
    "                             file5[0:304].reset_index(drop=True),\n",
    "                             file5[30304:60304].reset_index(drop=True)], axis = 0).reset_index(drop=True)\n",
    "hans = pd.concat([hans_premise, hans_hypothesis], axis = 1, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hans_premise, hans_hypothesis, file4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_diagnostics = pd.concat([file5[60304:61408].reset_index(drop=True),\n",
    "                             file5[61408:].reset_index(drop=True)], axis = 1, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del file5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write back to disk\n",
    "- Here again, ordering of operations based on availability of resources (memory and disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_diagnostics.to_csv('../data/features/nli_diagnostics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "del nli_diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hans.to_csv('../data/features/hans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_test.to_csv('../data/features/snli_test.csv')\n",
    "del snli_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_valid.to_csv('../data/features/snli_valid.csv')\n",
    "del snli_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_train.to_csv('../data/features/snli_train.csv')\n",
    "del snli_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
