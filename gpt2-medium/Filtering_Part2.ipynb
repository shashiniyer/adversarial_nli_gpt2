{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8edbca70",
   "metadata": {},
   "source": [
    "# Objective: Use AFLite to greedily solve for $\\text{arg min}_{S \\subset \\mathcal{D}, ~|S| \\geq n}\\mathcal{R}(\\Phi, ~S, ~\\mathcal{M})$\n",
    "\n",
    "### 1. Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfebceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, disable_caching\n",
    "from transformers import GPT2TokenizerFast, DataCollatorWithPadding, set_seed\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "import copy\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils_ import tokenize, train_classifier, predict, select_k\n",
    "import pickle\n",
    "import itertools\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "set_seed(42)\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78053619",
   "metadata": {},
   "source": [
    "### 2. Pre-Processing\n",
    "- Get SNLI Dataset (Train fold) and shuffle it using the same seed as used for obtaining GPT-2 based Feature Representation (see notebook [Filtering_Part1.ipynb](https://github.com/shashiniyer/adversarial_nli_gpt2/blob/main/Filtering_Part1.ipynb))\n",
    "- Remove instances without gold standard labels, i.e., label = -1\n",
    "- One-hot encoding for labels\n",
    "- Partition data 10%/90%; use the 90% as `train`\n",
    "- Tokenise train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62ad078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/shana92/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c831388287e64dc9994a8ce04871ae95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/551 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1f0a15bb1945fe8d6c977c62a06f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snli_train = load_dataset('snli', split = 'train').shuffle(seed = 42)\n",
    "snli_train = snli_train.filter(lambda x: x['label'] != -1).map( \\\n",
    "    lambda x: {'label': one_hot(torch.tensor(x['label']), 3).type(torch.float32).numpy()}, \\\n",
    "    batched = True)\n",
    "train = snli_train.select(range(int(len(snli_train)/10), len(snli_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9d6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up tokeniser\n",
    "# padding to left because GPT2 uses last token for prediction\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2-medium\", padding_side = 'left', \\\n",
    "                                              padding = True, truncation = True)\n",
    "tokenizer.pad_token = tokenizer.eos_token # pad with 'eos' token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2820639c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4499594a6e449daae2737d1314358d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/494431 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bf01b5d9f44dbba26493d316e78e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/495 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize data\n",
    "train = train.map(lambda x: tokenize(tokenizer, x['premise'] + '|' + x['hypothesis']))\n",
    "len_bef_exclusion = len(train)\n",
    "\n",
    "# exclude instances with > 128 tokens\n",
    "train = train.filter(lambda x: x['exclude'] == False)\n",
    "len_aft_exclusion = len(train)\n",
    "\n",
    "# print message if instances were in fact excluded\n",
    "if len_bef_exclusion - len_aft_exclusion > 0:\n",
    "    \n",
    "    print(f'{len_bef_exclusion - len_aft_exclusion} ' + \\\n",
    "          f'({(len_bef_exclusion/len_aft_exclusion - 1)*100:>2f}%) sequences excluded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12276e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only needed columns, set data format to PyTorch\n",
    "train.set_format(type = 'torch', columns = ['label', 'input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6458a",
   "metadata": {},
   "source": [
    "### 3. Set up inputs for AFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7048b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the feature representation, Phi, with linear layer attached\n",
    "model = torch.load('feature_rep.pth')\n",
    "\n",
    "# move model to CPU\n",
    "model.to('cpu')\n",
    "\n",
    "# freeze all layers except the last\n",
    "num_layers = sum(1 for _ in model.parameters())\n",
    "for idx, param in enumerate(model.parameters()):\n",
    "    \n",
    "    if idx != num_layers - 1:\n",
    "        \n",
    "        # freeze\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e87074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data collator - https://huggingface.co/docs/transformers/main_classes/data_collator\n",
    "# this is a (callable) helper object that sends batches of data to the model\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding = 'max_length', \\\n",
    "                                         return_tensors = 'pt', max_length = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c380ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters - constrained by training time available\n",
    "m = 30\n",
    "n = 195000\n",
    "t = 50000\n",
    "k = 100000\n",
    "tau = 0.75\n",
    "AFLite_seeds = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ff63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters for model training within AFLite implementation\n",
    "batch_size = 128 # constrained by GPU memory\n",
    "lr = 1e-5 # set to match Le et al. (2020) - https://arxiv.org/abs/2002.04108"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390eef5f",
   "metadata": {},
   "source": [
    "### 4.  AFLite Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25189fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0 - Iteration 1 - Model 1 - Begin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a794bd01746244f791835bbe5e7a2e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.351462  [    0/50000]\n",
      "loss: 0.339478  [ 4992/50000]\n",
      "loss: 0.323733  [ 9984/50000]\n",
      "loss: 0.371513  [14976/50000]\n",
      "loss: 0.327074  [19968/50000]\n",
      "loss: 0.414310  [24960/50000]\n",
      "loss: 0.360435  [29952/50000]\n",
      "loss: 0.316903  [34944/50000]\n",
      "loss: 0.329192  [39936/50000]\n",
      "loss: 0.394657  [44928/50000]\n",
      "loss: 0.372505  [31200/50000]\n",
      "Epoch average loss: 0.36408787965774536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b578ece3802a440ba88b5a245027f38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.384505  [    0/50000]\n",
      "loss: 0.419292  [ 4992/50000]\n",
      "loss: 0.439487  [ 9984/50000]\n",
      "loss: 0.422065  [14976/50000]\n",
      "loss: 0.387640  [19968/50000]\n",
      "loss: 0.368946  [24960/50000]\n",
      "loss: 0.349701  [29952/50000]\n",
      "loss: 0.391921  [34944/50000]\n",
      "loss: 0.347152  [39936/50000]\n",
      "loss: 0.438856  [44928/50000]\n",
      "loss: 0.348565  [31200/50000]\n",
      "Epoch average loss: 0.3647885024547577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bf5fe12f714dc589c8618f08653887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.370970  [    0/50000]\n",
      "loss: 0.397175  [ 4992/50000]\n",
      "loss: 0.425714  [ 9984/50000]\n",
      "loss: 0.365622  [14976/50000]\n",
      "loss: 0.376260  [19968/50000]\n",
      "loss: 0.401830  [24960/50000]\n",
      "loss: 0.397583  [29952/50000]\n",
      "loss: 0.368095  [34944/50000]\n",
      "loss: 0.393686  [39936/50000]\n",
      "loss: 0.346776  [44928/50000]\n",
      "loss: 0.398886  [31200/50000]\n",
      "Epoch average loss: 0.3642916977405548\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938f0be099b94ba5aa734e198b4d9f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3473 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0 - Iteration 1 - Model 1 - Done\n",
      "Seed 0 - Iteration 1 - Model 2 - Begin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eecd96007a24112ba1f442b37fd7bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.452623  [    0/50000]\n",
      "loss: 0.356459  [ 4992/50000]\n",
      "loss: 0.327671  [ 9984/50000]\n",
      "loss: 0.355331  [14976/50000]\n",
      "loss: 0.380826  [19968/50000]\n",
      "loss: 0.385904  [24960/50000]\n",
      "loss: 0.325877  [29952/50000]\n",
      "loss: 0.453212  [34944/50000]\n",
      "loss: 0.400007  [39936/50000]\n",
      "loss: 0.353646  [44928/50000]\n",
      "loss: 0.425990  [31200/50000]\n",
      "Epoch average loss: 0.3637206256389618\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e10905543d4c4da83d9a8e0c84097d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.401627  [    0/50000]\n",
      "loss: 0.381684  [ 4992/50000]\n",
      "loss: 0.378271  [ 9984/50000]\n",
      "loss: 0.373003  [14976/50000]\n",
      "loss: 0.325675  [19968/50000]\n",
      "loss: 0.369392  [24960/50000]\n",
      "loss: 0.430628  [29952/50000]\n",
      "loss: 0.337135  [34944/50000]\n",
      "loss: 0.329574  [39936/50000]\n",
      "loss: 0.341632  [44928/50000]\n",
      "loss: 0.334829  [31200/50000]\n",
      "Epoch average loss: 0.3633255660533905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c245873c034f33b8cf08fe5f88b997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.339411  [    0/50000]\n",
      "loss: 0.377477  [ 4992/50000]\n",
      "loss: 0.333938  [ 9984/50000]\n",
      "loss: 0.350429  [14976/50000]\n",
      "loss: 0.367987  [19968/50000]\n",
      "loss: 0.329853  [24960/50000]\n",
      "loss: 0.338207  [29952/50000]\n",
      "loss: 0.333629  [34944/50000]\n",
      "loss: 0.447789  [39936/50000]\n",
      "loss: 0.362146  [44928/50000]\n",
      "loss: 0.446653  [31200/50000]\n",
      "Epoch average loss: 0.3627510368824005\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c24fb909b645238b2e6e6e94ae5139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3473 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0 - Iteration 1 - Model 2 - Done\n",
      "Seed 0 - Iteration 1 - Model 3 - Begin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52420d2c7a5c4bf6ada00e6e5efe557f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.366838  [    0/50000]\n",
      "loss: 0.346938  [ 4992/50000]\n",
      "loss: 0.372451  [ 9984/50000]\n",
      "loss: 0.320485  [14976/50000]\n",
      "loss: 0.356794  [19968/50000]\n",
      "loss: 0.369373  [24960/50000]\n",
      "loss: 0.363575  [29952/50000]\n",
      "loss: 0.308874  [34944/50000]\n",
      "loss: 0.393721  [39936/50000]\n",
      "loss: 0.382872  [44928/50000]\n",
      "loss: 0.380604  [31200/50000]\n",
      "Epoch average loss: 0.36189162731170654\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb8a352f983446ba66ced7c3e12e872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.301175  [    0/50000]\n",
      "loss: 0.349950  [ 4992/50000]\n",
      "loss: 0.352163  [ 9984/50000]\n",
      "loss: 0.348009  [14976/50000]\n",
      "loss: 0.409791  [19968/50000]\n",
      "loss: 0.365269  [24960/50000]\n",
      "loss: 0.377372  [29952/50000]\n",
      "loss: 0.361114  [34944/50000]\n",
      "loss: 0.318849  [39936/50000]\n",
      "loss: 0.366322  [44928/50000]\n",
      "loss: 0.283538  [31200/50000]\n",
      "Epoch average loss: 0.3623788058757782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50480d7294142a08310e89df8c829d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.402654  [    0/50000]\n",
      "loss: 0.303437  [ 4992/50000]\n",
      "loss: 0.339138  [ 9984/50000]\n",
      "loss: 0.330377  [14976/50000]\n",
      "loss: 0.326630  [19968/50000]\n",
      "loss: 0.367296  [24960/50000]\n",
      "loss: 0.391380  [29952/50000]\n",
      "loss: 0.333377  [34944/50000]\n",
      "loss: 0.347316  [39936/50000]\n",
      "loss: 0.327635  [44928/50000]\n",
      "loss: 0.384607  [31200/50000]\n",
      "Epoch average loss: 0.36186596751213074\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04f5d5ca4fc465b88b5a27e7913d011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3473 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0 - Iteration 1 - Model 3 - Done\n",
      "Seed 0 - Iteration 1 - Model 4 - Begin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60aaa3de6bb246a99cb01f6441984a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.450345  [    0/50000]\n",
      "loss: 0.317346  [ 4992/50000]\n",
      "loss: 0.383968  [ 9984/50000]\n",
      "loss: 0.351726  [14976/50000]\n",
      "loss: 0.438074  [19968/50000]\n",
      "loss: 0.399947  [24960/50000]\n",
      "loss: 0.372646  [29952/50000]\n",
      "loss: 0.355177  [34944/50000]\n",
      "loss: 0.349292  [39936/50000]\n",
      "loss: 0.403655  [44928/50000]\n",
      "loss: 0.445391  [31200/50000]\n",
      "Epoch average loss: 0.36558693647384644\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec468f5424748fda5dafea27cce9ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.363079  [    0/50000]\n",
      "loss: 0.376719  [ 4992/50000]\n",
      "loss: 0.353817  [ 9984/50000]\n",
      "loss: 0.318308  [14976/50000]\n",
      "loss: 0.328502  [19968/50000]\n",
      "loss: 0.455255  [24960/50000]\n",
      "loss: 0.387360  [29952/50000]\n",
      "loss: 0.333444  [34944/50000]\n",
      "loss: 0.344278  [39936/50000]\n",
      "loss: 0.293226  [44928/50000]\n",
      "loss: 0.403219  [31200/50000]\n",
      "Epoch average loss: 0.3643246293067932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac3e7c2041949d1b7b70869910c241f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.395858  [    0/50000]\n",
      "loss: 0.365659  [ 4992/50000]\n",
      "loss: 0.390630  [ 9984/50000]\n",
      "loss: 0.324348  [14976/50000]\n",
      "loss: 0.278239  [19968/50000]\n",
      "loss: 0.363707  [24960/50000]\n",
      "loss: 0.341512  [29952/50000]\n",
      "loss: 0.475533  [34944/50000]\n",
      "loss: 0.366447  [39936/50000]\n",
      "loss: 0.297043  [44928/50000]\n",
      "loss: 0.362669  [31200/50000]\n",
      "Epoch average loss: 0.3626748323440552\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdd22255ec748fd8a1b958c233fa352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3473 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0 - Iteration 1 - Model 4 - Done\n",
      "Seed 0 - Iteration 1 - Model 5 - Begin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a316e975c8b4cb4a9a7c2f53fc14d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.354864  [    0/50000]\n",
      "loss: 0.423739  [ 4992/50000]\n",
      "loss: 0.302279  [ 9984/50000]\n",
      "loss: 0.379920  [14976/50000]\n",
      "loss: 0.327253  [19968/50000]\n",
      "loss: 0.316194  [24960/50000]\n",
      "loss: 0.353090  [29952/50000]\n",
      "loss: 0.371466  [34944/50000]\n",
      "loss: 0.357100  [39936/50000]\n",
      "loss: 0.318972  [44928/50000]\n",
      "loss: 0.248706  [31200/50000]\n",
      "Epoch average loss: 0.36417701840400696\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c474f7095ce49cbb34133c9e09afe98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.337895  [    0/50000]\n",
      "loss: 0.337823  [ 4992/50000]\n",
      "loss: 0.417160  [ 9984/50000]\n",
      "loss: 0.353334  [14976/50000]\n",
      "loss: 0.247678  [19968/50000]\n",
      "loss: 0.386853  [24960/50000]\n",
      "loss: 0.353052  [29952/50000]\n",
      "loss: 0.301107  [34944/50000]\n",
      "loss: 0.368206  [39936/50000]\n",
      "loss: 0.361346  [44928/50000]\n",
      "loss: 0.377103  [31200/50000]\n",
      "Epoch average loss: 0.363930344581604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6f7e775a634444905b0423e22019f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.437157  [    0/50000]\n",
      "loss: 0.371344  [ 4992/50000]\n",
      "loss: 0.338309  [ 9984/50000]\n",
      "loss: 0.340573  [14976/50000]\n",
      "loss: 0.400044  [19968/50000]\n",
      "loss: 0.385437  [24960/50000]\n",
      "loss: 0.421255  [29952/50000]\n",
      "loss: 0.399701  [34944/50000]\n",
      "loss: 0.279014  [39936/50000]\n",
      "loss: 0.359794  [44928/50000]\n",
      "loss: 0.394982  [31200/50000]\n",
      "Epoch average loss: 0.3622462749481201\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d050f322d454e43a35f468e796ca960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3473 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set up containers to collect outputs\n",
    "filtered_datasets = {}\n",
    "removed_idx = {x: '' for x in AFLite_seeds}\n",
    "\n",
    "# begin procedure\n",
    "for seed in AFLite_seeds:\n",
    "    \n",
    "    # first step of AFLite; initialise S\n",
    "    S = copy.deepcopy(train)\n",
    "    \n",
    "    # initialise iteration index\n",
    "    it_idx = 0\n",
    "    \n",
    "    while len(S) > n:\n",
    "        \n",
    "        # update iteration index\n",
    "        it_idx += 1\n",
    "        \n",
    "        # initialise multiset for Out-Of-Sample predictions\n",
    "        E = {x: [] for x in range(len(S))}\n",
    "\n",
    "        for j in range(m):\n",
    "            \n",
    "            # randomly partition S into (S\\T_j, T_j) s.t. |S\\T_j| = t\n",
    "            tr_idx = set(np.random.default_rng(j).choice(np.arange(len(S)), t, replace = False))\n",
    "            te_idx = set(range(len(S))) - tr_idx\n",
    "            tr, te = S.select(tr_idx), S.select(te_idx)\n",
    "            print(f'Seed {seed} - Iteration {it_idx} - Model {j + 1} - Begin')\n",
    "                        \n",
    "            # train classifier on S\\T_j, i.e. tr\n",
    "            classifier = copy.deepcopy(model)\n",
    "            dataloader = torch.utils.data.DataLoader(tr, batch_size=batch_size, \\\n",
    "                                 shuffle=True, collate_fn=data_collator)\n",
    "            optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()), lr = lr)\n",
    "            trained_classifier = train_classifier(classifier, dataloader, optimizer, device)\n",
    "            \n",
    "            # for all instances i in T_j, add predictions to E(i)\n",
    "            te_dataloader = torch.utils.data.DataLoader(te, batch_size=batch_size, collate_fn=data_collator)\n",
    "            preds = predict(trained_classifier, te_dataloader, device)\n",
    "            print(f'Seed {seed} - Iteration {it_idx} - Model {j + 1} - Done')\n",
    "            \n",
    "            for pred_idx, data_idx in enumerate(te_idx): # there are as many predictions as test instances\n",
    "                \n",
    "                E[data_idx] += [preds[pred_idx]]\n",
    "        \n",
    "        # for all instances in S, compute predictability score\n",
    "        # in the corner case that there are no predictions for an instance, we do not filter it out\n",
    "        lengths = torch.tensor([len(x) if len(x) > 0 else 1 for x in E.values()])\n",
    "        preds_padded = torch.tensor(list(itertools.zip_longest(*E.values(), fillvalue=-1))).transpose(0, 1)\n",
    "        labels = torch.repeat_interleave(S['label'].argmax(1), max(lengths)).reshape(preds_padded.size())\n",
    "\n",
    "        pred_matches = torch.eq(preds_padded, labels)\n",
    "        pred_match_totals = torch.sum(pred_matches, axis = 1)\n",
    "        pred_scores = pred_match_totals / lengths\n",
    "        \n",
    "        # select up to k instances with the highest predictability scores subject to score >= tau\n",
    "        selected_idx = select_k(pred_scores, tau, k, seed)\n",
    "        \n",
    "        if selected_idx.shape[0] > 0:\n",
    "        \n",
    "            # cache instances selected for removal\n",
    "            removed_idx[seed] += ',' + ','.join([str(idx) for idx in selected_idx])\n",
    "\n",
    "            # filter out selected instances\n",
    "            S = S.select(set(range(len(S))) - set(selected_idx))\n",
    "        \n",
    "        # early stopping\n",
    "        elif selected_idx.shape[0] < k:\n",
    "            \n",
    "            break\n",
    "    \n",
    "    # cache file\n",
    "    filtered_datasets[seed] = S\n",
    "    \n",
    "    # print number of instances in S, for creating random baseline\n",
    "    print(f'Number of instances in S (seed {seed}): {len(S)}')\n",
    "    \n",
    "# write out list of removed indices for further analysis\n",
    "with open('removed_idx.pkl', 'wb') as f:\n",
    "    pickle.dump(removed_idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5729ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out list of removed indices for further analysis\n",
    "with open('removed_idx.pkl', 'wb') as f:\n",
    "    pickle.dump(removed_idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c289bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
