{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8edbca70",
   "metadata": {},
   "source": [
    "# Dual Objective:\n",
    "- A) Use AFLite to greedily solve for $\\text{arg min}_{S \\subset \\mathcal{D}, ~|S| \\geq n}\\mathcal{R}(\\Phi, ~S, ~\\mathcal{M})$\n",
    "- B) Fine-tune GPT-2 with the resulting filtered dataset\n",
    "\n",
    "### 1. Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfebceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, disable_caching\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import GPT2TokenizerFast, DataCollatorWithPadding, set_seed\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "import copy\n",
    "import numpy as np\n",
    "from utils_ import tokenize, train_classifier, predict, select_k\n",
    "import pickle\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "set_seed(42)\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78053619",
   "metadata": {},
   "source": [
    "### 2. Pre-Processing\n",
    "- Get SNLI Dataset (Train fold) and shuffle it using the same seed as used for obtaining GPT-2 based Feature Representation (see notebook [Filtering_Part1.ipynb](https://github.com/shashiniyer/adversarial_nli_gpt2/blob/main/Filtering_Part1.ipynb))\n",
    "- Remove instances without gold standard labels, i.e., label = -1\n",
    "- One-hot encoding for labels\n",
    "- Partition data 10%/90%; use the 90% as `train`\n",
    "- Tokenise train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62ad078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/shana92/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6b9f3de9f74dc481d0d58857f8c993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/551 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0acf3a4c6b94fa79c21d508a7aeb6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snli_train = load_dataset('snli', split = 'train').shuffle(seed = 42)\n",
    "snli_train = snli_train.filter(lambda x: x['label'] != -1).map( \\\n",
    "    lambda x: {'label': one_hot(torch.tensor(x['label']), 3).type(torch.float32).numpy()}, \\\n",
    "    batched = True)\n",
    "train = snli_train.select(range(int(len(snli_train)/10), len(snli_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9d6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up tokeniser\n",
    "# padding to left because GPT2 uses last token for prediction\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\", padding_side = 'left', \\\n",
    "                                              padding = True, truncation = True)\n",
    "tokenizer.pad_token = tokenizer.eos_token # pad with 'eos' token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2820639c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfd39207ebe431bb39908eb3ea5c46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/494431 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbb8c957ea54927ab298f02111b56b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/495 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize data\n",
    "train = train.map(lambda x: tokenize(tokenizer, x['premise'] + '|' + x['hypothesis']))\n",
    "len_bef_exclusion = len(train)\n",
    "\n",
    "# exclude instances with > 128 tokens\n",
    "train = train.filter(lambda x: x['exclude'] == False)\n",
    "len_aft_exclusion = len(train)\n",
    "\n",
    "# print message if instances were in fact excluded\n",
    "if len_bef_exclusion - len_aft_exclusion > 0:\n",
    "    \n",
    "    print(f'{len_bef_exclusion - len_aft_exclusion} ' + \\\n",
    "          f'({(en_bef_exclusion/len_aft_exclusion - 1):>2f}%) sequences excluded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12276e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only needed columns, set data format to PyTorch\n",
    "train.set_format(type = 'torch', columns = ['label', 'input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6458a",
   "metadata": {},
   "source": [
    "### 3. Set up inputs for AFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7048b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the feature representation, Phi, with linear layer attached\n",
    "model = torch.load('feature_rep.pth')\n",
    "\n",
    "# move model to CPU\n",
    "model.to('cpu')\n",
    "\n",
    "# freeze all layers except the last\n",
    "num_layers = sum(1 for _ in model.parameters())\n",
    "for idx, param in enumerate(model.parameters()):\n",
    "    \n",
    "    if idx != num_layers - 1:\n",
    "        \n",
    "        # freeze\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e87074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data collator - https://huggingface.co/docs/transformers/main_classes/data_collator\n",
    "# this is a (callable) helper object that sends batches of data to the model\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding = 'max_length', \\\n",
    "                                         return_tensors = 'pt', max_length = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c380ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters - constrained by training time available\n",
    "m = 30\n",
    "n = 195000\n",
    "t = 50000\n",
    "k = 100000\n",
    "tau = 0.75\n",
    "AFLite_seeds = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ff63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters for model training within AFLite implementation\n",
    "batch_size = 128 # constrained by GPU memory\n",
    "lr = 1e-5 # set to match Le et al. (2020) - https://arxiv.org/abs/2002.04108"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390eef5f",
   "metadata": {},
   "source": [
    "### 4.  AFLite Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25189fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0 - Iteration 1 - Model 1 - Begin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127f4c08e7c24a04a41070e2ae56ec13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.490815  [    0/50000]\n",
      "loss: 0.462348  [ 4992/50000]\n",
      "loss: 0.483250  [ 9984/50000]\n",
      "loss: 0.501971  [14976/50000]\n",
      "loss: 0.445378  [19968/50000]\n",
      "loss: 0.507128  [24960/50000]\n",
      "loss: 0.435846  [29952/50000]\n",
      "loss: 0.411889  [34944/50000]\n",
      "loss: 0.481307  [39936/50000]\n",
      "loss: 0.452662  [44928/50000]\n",
      "loss: 0.496749  [31200/50000]\n",
      "Epoch average loss: 0.4680524170398712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bad3286fa64fc7a1c498e643b2efdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.488783  [    0/50000]\n",
      "loss: 0.467965  [ 4992/50000]\n",
      "loss: 0.482960  [ 9984/50000]\n",
      "loss: 0.464695  [14976/50000]\n",
      "loss: 0.479309  [19968/50000]\n",
      "loss: 0.460052  [24960/50000]\n",
      "loss: 0.459742  [29952/50000]\n",
      "loss: 0.501513  [34944/50000]\n",
      "loss: 0.476872  [39936/50000]\n",
      "loss: 0.534709  [44928/50000]\n",
      "loss: 0.460403  [31200/50000]\n",
      "Epoch average loss: 0.46620702743530273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da3a742ca084e7cb0f5b8d118ea8217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.439318  [    0/50000]\n",
      "loss: 0.496312  [ 4992/50000]\n",
      "loss: 0.486560  [ 9984/50000]\n",
      "loss: 0.445026  [14976/50000]\n",
      "loss: 0.457667  [19968/50000]\n",
      "loss: 0.512696  [24960/50000]\n",
      "loss: 0.515036  [29952/50000]\n",
      "loss: 0.453929  [34944/50000]\n",
      "loss: 0.412722  [39936/50000]\n",
      "loss: 0.464638  [44928/50000]\n",
      "loss: 0.542555  [31200/50000]\n",
      "Epoch average loss: 0.4677579998970032\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1901bc9b4e7b4a4eb129ccec2b4c8b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3473 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0 - Iteration 1 - Model 1 - Done\n",
      "Seed 0 - Iteration 1 - Model 2 - Begin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd00daf0ccb49048091f0aabda4e9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.496329  [    0/50000]\n",
      "loss: 0.461750  [ 4992/50000]\n",
      "loss: 0.414453  [ 9984/50000]\n",
      "loss: 0.499598  [14976/50000]\n",
      "loss: 0.489535  [19968/50000]\n",
      "loss: 0.493609  [24960/50000]\n",
      "loss: 0.491454  [29952/50000]\n",
      "loss: 0.517127  [34944/50000]\n",
      "loss: 0.455259  [39936/50000]\n",
      "loss: 0.461471  [44928/50000]\n",
      "loss: 0.489900  [31200/50000]\n",
      "Epoch average loss: 0.4648999571800232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959f6186359a4891ba679fbc020450cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.480835  [    0/50000]\n",
      "loss: 0.514182  [ 4992/50000]\n",
      "loss: 0.455320  [ 9984/50000]\n",
      "loss: 0.439934  [14976/50000]\n",
      "loss: 0.424020  [19968/50000]\n",
      "loss: 0.511567  [24960/50000]\n",
      "loss: 0.536579  [29952/50000]\n",
      "loss: 0.472423  [34944/50000]\n",
      "loss: 0.482909  [39936/50000]\n",
      "loss: 0.452261  [44928/50000]\n",
      "loss: 0.445191  [31200/50000]\n",
      "Epoch average loss: 0.46628013253211975\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a97e6c0de6d4aa6809071ed542b1831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.433838  [    0/50000]\n",
      "loss: 0.455367  [ 4992/50000]\n",
      "loss: 0.442342  [ 9984/50000]\n",
      "loss: 0.443768  [14976/50000]\n",
      "loss: 0.433495  [19968/50000]\n",
      "loss: 0.446716  [24960/50000]\n",
      "loss: 0.519018  [29952/50000]\n",
      "loss: 0.480844  [34944/50000]\n",
      "loss: 0.473903  [39936/50000]\n",
      "loss: 0.441200  [44928/50000]\n",
      "loss: 0.526351  [31200/50000]\n",
      "Epoch average loss: 0.46541374921798706\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142e6699de4444e29c4ced0ae41b3938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3473 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0 - Iteration 1 - Model 2 - Done\n",
      "Seed 0 - Iteration 1 - Model 3 - Begin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3a4f9349274fb5a8bb6015b4f6edf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.468877  [    0/50000]\n",
      "loss: 0.444588  [ 4992/50000]\n",
      "loss: 0.463039  [ 9984/50000]\n",
      "loss: 0.452809  [14976/50000]\n",
      "loss: 0.475705  [19968/50000]\n",
      "loss: 0.507545  [24960/50000]\n",
      "loss: 0.442597  [29952/50000]\n",
      "loss: 0.422230  [34944/50000]\n",
      "loss: 0.504980  [39936/50000]\n",
      "loss: 0.464689  [44928/50000]\n",
      "loss: 0.475628  [31200/50000]\n",
      "Epoch average loss: 0.4662174582481384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f47d8407a2407382f360bb2822f4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.434559  [    0/50000]\n",
      "loss: 0.472283  [ 4992/50000]\n",
      "loss: 0.515166  [ 9984/50000]\n",
      "loss: 0.440969  [14976/50000]\n",
      "loss: 0.435638  [19968/50000]\n",
      "loss: 0.420971  [24960/50000]\n",
      "loss: 0.485145  [29952/50000]\n",
      "loss: 0.495289  [34944/50000]\n",
      "loss: 0.464453  [39936/50000]\n",
      "loss: 0.464244  [44928/50000]\n",
      "loss: 0.437880  [31200/50000]\n",
      "Epoch average loss: 0.4661409258842468\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b479a4b1e326445ba4eb321ff52045b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.471737  [    0/50000]\n",
      "loss: 0.412788  [ 4992/50000]\n",
      "loss: 0.467256  [ 9984/50000]\n",
      "loss: 0.425003  [14976/50000]\n",
      "loss: 0.399822  [19968/50000]\n",
      "loss: 0.389849  [24960/50000]\n",
      "loss: 0.456639  [29952/50000]\n",
      "loss: 0.413032  [34944/50000]\n",
      "loss: 0.473176  [39936/50000]\n",
      "loss: 0.409610  [44928/50000]\n",
      "loss: 0.495577  [31200/50000]\n",
      "Epoch average loss: 0.46622443199157715\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7845c4e2e3724ed1bafc5f5ce60f5a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3473 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0 - Iteration 1 - Model 3 - Done\n",
      "Seed 0 - Iteration 1 - Model 4 - Begin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ee519c42a548ca8d03e71fa0b4b1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.482670  [    0/50000]\n",
      "loss: 0.467089  [ 4992/50000]\n",
      "loss: 0.488443  [ 9984/50000]\n",
      "loss: 0.473134  [14976/50000]\n",
      "loss: 0.512105  [19968/50000]\n",
      "loss: 0.512495  [24960/50000]\n",
      "loss: 0.485099  [29952/50000]\n",
      "loss: 0.429189  [34944/50000]\n",
      "loss: 0.452853  [39936/50000]\n",
      "loss: 0.462465  [44928/50000]\n",
      "loss: 0.515317  [31200/50000]\n",
      "Epoch average loss: 0.466852605342865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a704d54adc42c59ed89527d206932d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.485342  [    0/50000]\n",
      "loss: 0.458100  [ 4992/50000]\n",
      "loss: 0.455437  [ 9984/50000]\n",
      "loss: 0.439894  [14976/50000]\n",
      "loss: 0.443444  [19968/50000]\n",
      "loss: 0.519521  [24960/50000]\n",
      "loss: 0.455382  [29952/50000]\n",
      "loss: 0.451171  [34944/50000]\n",
      "loss: 0.459446  [39936/50000]\n",
      "loss: 0.459204  [44928/50000]\n",
      "loss: 0.475304  [31200/50000]\n",
      "Epoch average loss: 0.4650052487850189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3118c72a8265426095be3f822ecadad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.533792  [    0/50000]\n",
      "loss: 0.471606  [ 4992/50000]\n",
      "loss: 0.526378  [ 9984/50000]\n",
      "loss: 0.412952  [14976/50000]\n",
      "loss: 0.413553  [19968/50000]\n",
      "loss: 0.475280  [24960/50000]\n",
      "loss: 0.390599  [29952/50000]\n",
      "loss: 0.534704  [34944/50000]\n",
      "loss: 0.460793  [39936/50000]\n",
      "loss: 0.422744  [44928/50000]\n",
      "loss: 0.466432  [31200/50000]\n",
      "Epoch average loss: 0.4644717574119568\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10f9ec58b54464e9b3d910ae94b5679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3473 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set up containers to collect outputs\n",
    "filtered_datasets = {}\n",
    "removed_idx = {x: '' for x in AFLite_seeds}\n",
    "\n",
    "# begin procedure\n",
    "for seed in AFLite_seeds:\n",
    "    \n",
    "    # first step of AFLite; initialise S\n",
    "    S = copy.deepcopy(train)\n",
    "    \n",
    "    # initialise iteration index\n",
    "    it_idx = 0\n",
    "    \n",
    "    while len(S) > n:\n",
    "        \n",
    "        # update iteration index\n",
    "        it_idx += 1\n",
    "        \n",
    "        # initialise multiset for Out-Of-Sample predictions\n",
    "        E = {x: [] for x in range(len(S))}\n",
    "\n",
    "        for j in range(m):\n",
    "            \n",
    "            # randomly partition S into (S\\T_j, T_j) s.t. |S\\T_j| = t\n",
    "            tr_idx = set(np.random.default_rng(j).choice(np.arange(len(S)), t, replace = False))\n",
    "            te_idx = set(range(len(S))) - tr_idx\n",
    "            tr, te = S.select(tr_idx), S.select(te_idx)\n",
    "            print(f'Seed {seed} - Iteration {it_idx} - Model {j + 1} - Begin')\n",
    "                        \n",
    "            # train classifier on S\\T_j, i.e. tr\n",
    "            classifier = copy.deepcopy(model)\n",
    "            dataloader = torch.utils.data.DataLoader(tr, batch_size=batch_size, \\\n",
    "                                 shuffle=True, collate_fn=data_collator)\n",
    "            optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()), lr = lr)\n",
    "            trained_classifier = train_classifier(classifier, dataloader, optimizer, device)\n",
    "            \n",
    "            # for all instances i in T_j, add predictions to E(i)\n",
    "            te_dataloader = torch.utils.data.DataLoader(te, batch_size=batch_size, collate_fn=data_collator)\n",
    "            preds = predict(trained_classifier, te_dataloader, device)\n",
    "            print(f'Seed {seed} - Iteration {it_idx} - Model {j + 1} - Done')\n",
    "            \n",
    "            for pred_idx, data_idx in enumerate(te_idx): # there are as many predictions as test instances\n",
    "                \n",
    "                E[data_idx] += [preds[pred_idx]]\n",
    "        \n",
    "        # for all instances in S, compute predictability score\n",
    "        # in the corner case that there are no predictions for an instance, we do not filter it out\n",
    "        pred_scores = [0 if len(x) == 0 else sum([1 for y_hat in x if y_hat == S[idx]['label']])/len(x) \\\n",
    "                       for idx, x in enumerate(E.values())]\n",
    "        \n",
    "        # select up to k instances with the highest predictability scores subject to score >= tau\n",
    "        selected_idx = select_k(pred_scores, tau, k, seed)\n",
    "        \n",
    "        if selected_idx.shape[0] > 0:\n",
    "        \n",
    "            # cache instances selected for removal\n",
    "            removed_idx[seed] += ',' + ','.join([str(idx) for idx in selected_idx])\n",
    "\n",
    "            # filter out selected instances\n",
    "            S = S.select(set(range(len(S))) - set(selected_idx))\n",
    "        \n",
    "        # early stopping\n",
    "        elif selected_idx.shape[0] < k:\n",
    "            \n",
    "            break\n",
    "    \n",
    "    # cache file\n",
    "    filtered_datasets[seed] = S\n",
    "    \n",
    "    # print number of instances in S, for creating random baseline\n",
    "    print(f'Number of instances in S (seed {seed}): {len(S)}')\n",
    "    \n",
    "# write out list of removed indices for further analysis\n",
    "with open('removed_idx.pkl', 'wb') as f:\n",
    "    pickle.dump(removed_idx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b982e",
   "metadata": {},
   "source": [
    "### 5. Fine-tuning GPT-2 with AFLite filtered datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b094b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up some RAM\n",
    "del train \n",
    "del model\n",
    "del classifier\n",
    "\n",
    "# Begin fine-tuning\n",
    "for seed in AFLite_seeds:\n",
    "    \n",
    "    # instantiate new GPT-2 based model\n",
    "    model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", \n",
    "                                      num_labels=3,\n",
    "                                      problem_type=\"multi_label_classification\")\n",
    "    model.config.pad_token_id = model.config.eos_token_id # specify pad_token used by tokenizer\n",
    "    \n",
    "    # set up data loader\n",
    "    dataloader = torch.utils.data.DataLoader(filtered_datasets[seed], batch_size=batch_size, \\\n",
    "                                             shuffle=True, collate_fn=data_collator)\n",
    "    \n",
    "    # set up optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)    \n",
    "    \n",
    "    # fine-tune model\n",
    "    torch.save(train_classifier(model, dataloader, optimizer, device), \\\n",
    "              'AFLite_fine_tuned_model_seed' + str(seed) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789a0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
