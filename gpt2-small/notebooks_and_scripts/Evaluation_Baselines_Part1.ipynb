{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6016ff83",
   "metadata": {},
   "source": [
    "# Evaluate Performance of Baseline Models - Part 1\n",
    "__Model performance will be evaluated on:__\n",
    "1. In-Distribution sample (SNLI test split), in zero-shot settings (_this notebook_)\n",
    "2. The following Out-of-Distribution samples:\n",
    "    - HANS dataset (validation split), in zero-shot settings (_this notebook_)\n",
    "    - NLI Diagnostics dataset, in zero-shot settings (_this notebook_)\n",
    "    - Stress Test datasets, in zero-shot settings (_this notebook_)\n",
    "    - ANLI datasets (test splits), after fine-tuning the model for each round (see [Part 2](https://github.com/shashiniyer/adversarial_nli_gpt2/blob/main/gpt2-small/notebooks_and_scripts/Evaluation_Baselines_Part2.ipynb))\n",
    "\n",
    "__Performance indicators:__ Classification accuracy and $R_K$\n",
    "\n",
    "\n",
    "## 1. Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4fbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, disable_caching, Dataset\n",
    "from transformers import GPT2TokenizerFast, DataCollatorWithPadding, set_seed\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "import numpy as np\n",
    "from utils_ import tokenize, evaluate_acc_rk\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "set_seed(42)\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de5b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up tokeniser\n",
    "# padding to left because GPT2 uses last token for prediction\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\", padding_side = 'left', \\\n",
    "                                              padding = True, truncation = True)\n",
    "tokenizer.pad_token = tokenizer.eos_token # pad with 'eos' token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57213f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data collator - https://huggingface.co/docs/transformers/main_classes/data_collator\n",
    "# this is a (callable) helper object that sends batches of data to the model\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding = 'max_length', \\\n",
    "                                         return_tensors = 'pt', max_length = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3665ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models and set them in evaluation model, if needed\n",
    "model1 = torch.load('baseline_unfiltered.pth')\n",
    "model2 = torch.load('baseline_random_190k.pth')\n",
    "\n",
    "if model1.training:\n",
    "\n",
    "    model1.eval()\n",
    "\n",
    "if model2.training:\n",
    "\n",
    "    model2.eval()\n",
    "\n",
    "# set up dictionary of the models\n",
    "models = {'Unfiltered': model1, 'Random 190k Subset': model2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9386466",
   "metadata": {},
   "source": [
    "## 2. In-Distribution Evaluation - SNLI test - Zero-Shot\n",
    "### 2.1. Data Read + Pre-Processing\n",
    "- Get SNLI Dataset (test split)\n",
    "- One-hot encode labels\n",
    "- Remove instances without gold standard labels, i.e., label = -1\n",
    "- Tokenise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c8d2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/shana92/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd2f5c890044077ae6471d8daab012a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd36f7165bd49f1b71218dd56e69427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e76bad283cd4a8cbe9e28cce8c68546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9824 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61d291a5bad4e3887631d6939397feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in data\n",
    "snli_test = load_dataset('snli', split = 'test')\n",
    "snli_test = snli_test.filter(lambda x: x['label'] != -1).map( \\\n",
    "    lambda x: {'label': one_hot(torch.tensor(x['label']), 3).type(torch.float32).numpy()}, \\\n",
    "    batched = True)\n",
    "\n",
    "# tokenize data\n",
    "snli_test = snli_test.map(lambda x: tokenize(tokenizer, x['premise'] + '|' + x['hypothesis']))\n",
    "len_bef_exclusion = len(snli_test)\n",
    "\n",
    "# exclude instances with > 128 tokens\n",
    "snli_test = snli_test.filter(lambda x: x['exclude'] == False)\n",
    "len_aft_exclusion = len(snli_test)\n",
    "\n",
    "# print message if instances were in fact excluded\n",
    "if len_bef_exclusion - len_aft_exclusion > 0:\n",
    "    \n",
    "    print(f'{len_bef_exclusion - len_aft_exclusion} ' + \\\n",
    "          f'({(len_bef_exclusion/len_aft_exclusion - 1)*100:>2f}%) sequences excluded')\n",
    "\n",
    "# format data as torch tensors\n",
    "snli_test.set_format(type = 'torch', columns = ['label', 'input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5460596",
   "metadata": {},
   "source": [
    "### 2.2. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b809f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a2acee81ea4df9aac46a73161ebad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unfiltered - Dataset: SNLI (test) - Accuracy: 85.586321%, RK: 0.784716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182a8a62d4c8447ca6c239485da366e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random 190k Subset - Dataset: SNLI (test) - Accuracy: 79.509366%, RK: 0.694449\n"
     ]
    }
   ],
   "source": [
    "# set up dataloader (batch generator)\n",
    "dataloader = torch.utils.data.DataLoader(snli_test, batch_size=128, collate_fn=data_collator)\n",
    "\n",
    "# evaluate models\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    acc, rk = evaluate_acc_rk(model, dataloader, device)\n",
    "    print(f'Model: {model_name} - Dataset: SNLI (test) - Accuracy: {acc*100:>3f}%, RK: {rk:>3f}')\n",
    "\n",
    "# free up some RAM\n",
    "del snli_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41495cad",
   "metadata": {},
   "source": [
    "## 3. Out-of-Distribution Evaluation - HANS - Zero-Shot\n",
    "### 3.1. Data Read + Pre-Processing\n",
    "- Get HANS Dataset (validation split)\n",
    "- One-hot encode labels\n",
    "- Remove instances without gold standard labels, i.e., label = -1\n",
    "- Tokenise data\n",
    "- Partition the data by `heuristic`; categories are `constituent`, `lexical_overlap`, `subsequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e006fe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hans (/home/shana92/.cache/huggingface/datasets/hans/plain_text/1.0.0/452e93cf5383f5ae39088254215b517d0da98ccaaf0af8f7ab04d8f23f67dbd9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed13ab1f426e4871b163a8451a7c77ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28afce97d1546dc922a07dbf072acb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08d545e92b14126aed0e7d6daa39e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c8e8824fa84115847a4b697bb32d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a29b29cb02b40e89a2de76c39b3b983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f56de8f7c848788c729bd1b681bf0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1268a61f92df4a32a523d5d3c344773a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in data\n",
    "hans = load_dataset('hans', split = 'validation')\n",
    "hans = hans.filter(lambda x: x['label'] != -1).map( \\\n",
    "    lambda x: {'label': one_hot(torch.tensor(x['label']), 3).type(torch.float32).numpy()}, \\\n",
    "    batched = True)\n",
    "\n",
    "# tokenize data\n",
    "hans = hans.map(lambda x: tokenize(tokenizer, x['premise'] + '|' + x['hypothesis']))\n",
    "len_bef_exclusion = len(hans)\n",
    "\n",
    "# exclude instances with > 128 tokens\n",
    "hans = hans.filter(lambda x: x['exclude'] == False)\n",
    "len_aft_exclusion = len(hans)\n",
    "\n",
    "# print message if instances were in fact excluded\n",
    "if len_bef_exclusion - len_aft_exclusion > 0:\n",
    "    \n",
    "    print(f'{len_bef_exclusion - len_aft_exclusion} ' + \\\n",
    "          f'({(len_bef_exclusion/len_aft_exclusion - 1)*100:>2f}%) sequences excluded')\n",
    "\n",
    "# partition data by `heuristic` \n",
    "data_dict = {x: hans.filter(lambda y: y['heuristic'] == x) \\\n",
    "            for x in ['constituent', 'lexical_overlap', 'subsequence']}\n",
    "\n",
    "# format as torch tensors\n",
    "for val in data_dict.values():\n",
    "    \n",
    "    val.set_format(type = 'torch', columns = ['label', 'input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18c9db9",
   "metadata": {},
   "source": [
    "### 3.2. Load model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a97fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61aeff6dd6354ebeb26819394039a5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unfiltered - Dataset: constituent - Accuracy: 49.970001%, RK: -0.008326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7119901c1e22421cb208549afa5fbb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random 190k Subset - Dataset: constituent - Accuracy: 49.739999%, RK: -0.018851\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013c957fc923481c809f598e9d39c1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unfiltered - Dataset: lexical_overlap - Accuracy: 50.010002%, RK: 0.010000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff366a5997a4229a5b46d21f04c1b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random 190k Subset - Dataset: lexical_overlap - Accuracy: 50.000000%, RK: 0.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0366639f95b54d5dac7f7696c6797cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unfiltered - Dataset: subsequence - Accuracy: 50.000000%, RK: 0.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac96910f67b4da09ed7c1c0ebd4f6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random 190k Subset - Dataset: subsequence - Accuracy: 49.980000%, RK: -0.010002\n"
     ]
    }
   ],
   "source": [
    "for data_name, data in data_dict.items():\n",
    "    \n",
    "    # set up dataloader (batch generator)\n",
    "    dataloader = torch.utils.data.DataLoader(data, batch_size=128, collate_fn=data_collator)\n",
    "\n",
    "    # evaluate models\n",
    "    for model_name, model in models.items():\n",
    "        \n",
    "        acc, rk = evaluate_acc_rk(model, dataloader, device, problem = 'TE')\n",
    "        print(f'Model: {model_name} - Dataset: {data_name} - Accuracy: {acc*100:>3f}%, RK: {rk:>3f}')\n",
    "\n",
    "# free up some RAM\n",
    "del hans\n",
    "del data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307de6d",
   "metadata": {},
   "source": [
    "## 4. Out-of-Distribution Evaluation - NLI Diagnostics - Zero-Shot\n",
    "### 4.1. Data Read + Pre-Processing\n",
    "- Get NLI Diagnostics Dataset\n",
    "- One-hot encode labels\n",
    "- Tokenise data\n",
    "- Partition data by heuristic type - `Lexical Semantics`, `Predicate-Argument Structure`, `Logic`, `Knowledge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c5400a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d177ba0dfdd14a69aeade63ddf07235a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7b4bc45fd346f8862e83fba4fe7c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a7ed00095c429b903dfed018d33a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d19c51f14a74738b8f48fa5cc7855d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb940655faf44bfaa71ad1ba08f2dd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36a45f6a3754984b4cd7ae7a53f23da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2c51e8862f4d058ee5b1d180b43ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in data\n",
    "nli_diag = Dataset.from_pandas(pd.read_csv('./raw_data/diagnostic-full.tsv', delimiter = '\\t'))\n",
    "text_label_encoder = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n",
    "nli_diag = nli_diag.map( \\\n",
    "    lambda x: {'label': one_hot(torch.tensor(text_label_encoder[x['Label']]), 3).type(torch.float32).numpy()})\n",
    "\n",
    "# tokenize data\n",
    "nli_diag = nli_diag.map(lambda x: tokenize(tokenizer, x['Premise'] + '|' + x['Hypothesis']))\n",
    "len_bef_exclusion = len(nli_diag)\n",
    "\n",
    "# exclude instances with > 128 tokens\n",
    "nli_diag = nli_diag.filter(lambda x: x['exclude'] == False)\n",
    "len_aft_exclusion = len(nli_diag)\n",
    "\n",
    "# print message if instances were in fact excluded\n",
    "if len_bef_exclusion - len_aft_exclusion > 0:\n",
    "    \n",
    "    print(f'{len_bef_exclusion - len_aft_exclusion} ' + \\\n",
    "          f'({(len_bef_exclusion/len_aft_exclusion - 1)*100:>2f}%) sequences excluded')\n",
    "\n",
    "# partition data by heuristic\n",
    "data_dict = {x: nli_diag.filter(lambda y: y[x] is not None) \\\n",
    "            for x in ['Lexical Semantics', 'Predicate-Argument Structure', 'Logic', 'Knowledge']}\n",
    "\n",
    "# format as torch tensors\n",
    "for val in data_dict.values():\n",
    "    \n",
    "    val.set_format(type = 'torch', columns = ['label', 'input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ff2a7",
   "metadata": {},
   "source": [
    "### 4.2. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f51a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9df3804a354eaea0af0d37f5b31a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unfiltered - Dataset: Lexical Semantics - Accuracy: 44.293478%, RK: 0.136317\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4c2fbe8e7f4d6fb8e41850fe7f2d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random 190k Subset - Dataset: Lexical Semantics - Accuracy: 44.021741%, RK: 0.113212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e8f7b2e54c4ce7a03d6f745ea41e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unfiltered - Dataset: Predicate-Argument Structure - Accuracy: 52.830189%, RK: 0.189751\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac58d67dc4fd4c4ca949362f3b6393eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random 190k Subset - Dataset: Predicate-Argument Structure - Accuracy: 55.660379%, RK: 0.220542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d68c93842c04eb09e4e1dd8f9010206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unfiltered - Dataset: Logic - Accuracy: 42.032966%, RK: 0.124104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247f1e508f124c168b5380bfee07e7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random 190k Subset - Dataset: Logic - Accuracy: 41.758242%, RK: 0.114731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a4333eb4174a679ec154d143da088d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unfiltered - Dataset: Knowledge - Accuracy: 36.971831%, RK: 0.063335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d9b4644b744df2a7ed46a2bb70cdb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random 190k Subset - Dataset: Knowledge - Accuracy: 38.380283%, RK: 0.099242\n"
     ]
    }
   ],
   "source": [
    "for data_name, data in data_dict.items():\n",
    "    \n",
    "    # set up dataloader (batch generator)\n",
    "    dataloader = torch.utils.data.DataLoader(data, batch_size=128, collate_fn=data_collator)\n",
    "\n",
    "    # evaluate models\n",
    "    for model_name, model in models.items():\n",
    "        \n",
    "        acc, rk = evaluate_acc_rk(model, dataloader, device)\n",
    "        print(f'Model: {model_name} - Dataset: {data_name} - Accuracy: {acc*100:>3f}%, RK: {rk:>3f}')\n",
    "\n",
    "# free up some RAM\n",
    "del nli_diag\n",
    "del data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1bc9b7",
   "metadata": {},
   "source": [
    "## 5. Out-of-Distribution Evaluation - Stress Tests - Zero-Shot\n",
    "### 5.1. Data Read + Pre-Processing\n",
    "- Get Stress Test Datasets\n",
    "- Partition data by heuristic type:\n",
    "    - `Competence` to consist of the datasets `antonym_matched`, `antonym_mismatched`, `quant_hard`\n",
    "    - `Distraction` to consist of the datasets `taut2_matched`, `taut2_mismatched`, `negation_matched`,`negation_mismatched`, `length_mismatch_matched`, `length_mismatch_mismatched`\n",
    "    - `Noise` to consist of the datasets `dev_gram_functionword_swap_perturbed_matched`, `dev_gram_keyboard_matched`, `dev_gram_functionword_swap_perturbed_mismatched`, `dev_gram_swap_mismatched`,\n",
    " `dev_gram_keyboard_mismatched`, `dev_gram_swap_matched`, `dev_gram_contentword_swap_perturbed_mismatched`, `dev_gram_contentword_swap_perturbed_matched`\n",
    "- One-hot encode labels\n",
    "- Tokenise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b56d0517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1: antonym_matched - Begin\n",
      "File 1: antonym_matched - End\n",
      "File 2: antonym_mismatched - Begin\n",
      "File 2: antonym_mismatched - End\n",
      "File 3: quant_hard - Begin\n",
      "File 3: quant_hard - End\n",
      "File 4: taut2_mismatched - Begin\n",
      "File 4: taut2_mismatched - End\n",
      "File 5: taut2_matched - Begin\n",
      "File 5: taut2_matched - End\n",
      "File 6: length_mismatch_matched - Begin\n",
      "File 6: length_mismatch_matched - End\n",
      "File 7: length_mismatch_mismatched - Begin\n",
      "File 7: length_mismatch_mismatched - End\n",
      "File 8: dev_gram_functionword_swap_perturbed_matched - Begin\n",
      "File 8: dev_gram_functionword_swap_perturbed_matched - End\n",
      "File 9: dev_gram_keyboard_matched - Begin\n",
      "File 9: dev_gram_keyboard_matched - End\n",
      "File 10: dev_gram_functionword_swap_perturbed_mismatched - Begin\n",
      "File 10: dev_gram_functionword_swap_perturbed_mismatched - End\n",
      "File 11: dev_gram_swap_mismatched - Begin\n",
      "File 11: dev_gram_swap_mismatched - End\n",
      "File 12: dev_gram_keyboard_mismatched - Begin\n",
      "File 12: dev_gram_keyboard_mismatched - End\n",
      "File 13: dev_gram_swap_matched - Begin\n",
      "File 13: dev_gram_swap_matched - End\n",
      "File 14: dev_gram_contentword_swap_perturbed_mismatched - Begin\n",
      "File 14: dev_gram_contentword_swap_perturbed_mismatched - End\n",
      "File 15: dev_gram_contentword_swap_perturbed_matched - Begin\n",
      "File 15: dev_gram_contentword_swap_perturbed_matched - End\n",
      "File 16: negation_mismatched - Begin\n",
      "File 16: negation_mismatched - End\n",
      "File 17: negation_matched - Begin\n",
      "File 17: negation_matched - End\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ffd993eace48a9b295c603c39d4f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24071 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b93449698e4bbd9f0233c49ff98a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24071 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b142fb5ff6b3408db8037d325512c253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic: Competence - 396 (1.672650%) sequences excluded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055ac018126d4351a3dadacaed30af52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294705 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934e25c06d45409a92955277b4e014c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294705 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297067e5c5cb49839a37ed72885819e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/295 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic: Distraction - 1060 (0.360980%) sequences excluded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d937a91919044e2a98e3d8a0c7618ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/333160 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb645010145a411b8f60dcd033fdeca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/333160 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e30c6172d4a45178f846366f566d357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic: Noise - 1070 (0.322202%) sequences excluded\n"
     ]
    }
   ],
   "source": [
    "# load in files from './raw_data/Stress Tests/'\n",
    "stress_tests_datasets = {}  \n",
    "count = 0\n",
    "\n",
    "for path, subdirs, files in os.walk('./raw_data/Stress Tests/'):\n",
    "\n",
    "    for name in files:\n",
    "        \n",
    "        if name.endswith('.jsonl'):\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            dict_key = name.replace('multinli_0.9_', '').replace('.jsonl', '')\n",
    "            \n",
    "            print('File ' + str(count) + ': ' + dict_key + ' - Begin')\n",
    "        \n",
    "            with open(os.path.join(path, name), 'r') as json_file:\n",
    "                \n",
    "                json_list = list(json_file)\n",
    "            \n",
    "            if list in [type(x) for x in json.loads(json_list[0]).values()]:\n",
    "            \n",
    "                df = pd.DataFrame(json.loads(json_list[0]))\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                df = pd.DataFrame(json.loads(json_list[0]), index = [0])\n",
    "            \n",
    "            for i in range(1, len(json_list)):\n",
    "                \n",
    "                if list in [type(x) for x in json.loads(json_list[i]).values()]:\n",
    "                \n",
    "                    df = pd.concat([df, pd.DataFrame(json.loads(json_list[i]))], axis = 0)\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    df = pd.concat([df, pd.DataFrame(json.loads(json_list[i]), index = [0])], axis = 0)\n",
    "            \n",
    "            stress_tests_datasets[dict_key] = df.reset_index()\n",
    "            print('File ' + str(count) + ': ' + dict_key + ' - End')\n",
    "\n",
    "# retain only necessary columns\n",
    "for k, v in stress_tests_datasets.items():\n",
    "    \n",
    "    stress_tests_datasets[k] = v.loc[:, ['gold_label', 'sentence1', 'sentence2']]\n",
    "\n",
    "# utility function to concatenate datasets and return 'datasets.Dataset' in torch format\n",
    "def conc_prep_datasets(heuristic, key_list):\n",
    "    \n",
    "    # concat datasets\n",
    "    out = stress_tests_datasets[key_list[0]]\n",
    "    \n",
    "    for key in key_list[1:]:\n",
    "        \n",
    "        out = pd.concat([out, stress_tests_datasets[key]], axis = 0)\n",
    "    \n",
    "    # one-hot encode labels\n",
    "    out = Dataset.from_pandas(out).map(lambda x: \\\n",
    "        {'label': one_hot(torch.tensor(text_label_encoder[x['gold_label']]), 3).type(torch.float32).numpy()})\n",
    "    \n",
    "    # tokenize\n",
    "    out = out.map(lambda x: tokenize(tokenizer, x['sentence1'] + '|' + x['sentence2']))\n",
    "    len_bef_exclusion = len(out)\n",
    "    \n",
    "    # exclude instances with > 128 tokens\n",
    "    out = out.filter(lambda x: x['exclude'] == False)\n",
    "    len_aft_exclusion = len(out)\n",
    "\n",
    "    # print message if instances were in fact excluded\n",
    "    if len_bef_exclusion - len_aft_exclusion > 0:\n",
    "\n",
    "        print(f'Heuristic: {heuristic} - {len_bef_exclusion - len_aft_exclusion} ' + \\\n",
    "              f'({(len_bef_exclusion/len_aft_exclusion - 1)*100:>2f}%) sequences excluded')\n",
    "    \n",
    "    # format data as torch tensors\n",
    "    out.set_format(type = 'torch', columns = ['label', 'input_ids', 'attention_mask'])\n",
    "    \n",
    "    return(out)\n",
    "    \n",
    "# partition data by heuristic + pre-process them\n",
    "data_dict = {'Competence': conc_prep_datasets('Competence', \\\n",
    "                                              ['antonym_matched', 'antonym_mismatched', 'quant_hard']), \\\n",
    "             'Distraction': conc_prep_datasets('Distraction', \\\n",
    "                             ['taut2_matched', 'taut2_mismatched', 'negation_matched', 'negation_mismatched', \\\n",
    "                             'length_mismatch_matched', 'length_mismatch_mismatched']), \\\n",
    "             'Noise': conc_prep_datasets('Noise', \\\n",
    "                                         [k for k in stress_tests_datasets.keys() if k.startswith('dev_gram')])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fef03d",
   "metadata": {},
   "source": [
    "### 5.2. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3829fea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a3339b8d8b401897970ab2b602d16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/185 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unfiltered - Dataset: Competence - Accuracy: 31.146780%, RK: -0.152137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb121e9557054299997232de3befda0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/185 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random 190k Subset - Dataset: Competence - Accuracy: 16.650476%, RK: -0.027042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0bc33ebb9f47c4aa2bf30ca8211bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unfiltered - Dataset: Distraction - Accuracy: 48.737422%, RK: 0.254121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53918c5cddfe4b3f8e0d2ea5d68da71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random 190k Subset - Dataset: Distraction - Accuracy: 45.234892%, RK: 0.205363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557f3e0f8eb147d180a31d07742ae4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unfiltered - Dataset: Noise - Accuracy: 55.968261%, RK: 0.345760\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7e0d757cf14c58b033222b09b5a006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random 190k Subset - Dataset: Noise - Accuracy: 49.579933%, RK: 0.265181\n"
     ]
    }
   ],
   "source": [
    "for data_name, data in data_dict.items():\n",
    "    \n",
    "    # set up dataloader (batch generator)\n",
    "    dataloader = torch.utils.data.DataLoader(data, batch_size=128, collate_fn=data_collator)\n",
    "\n",
    "    # evaluate models\n",
    "    for model_name, model in models.items():\n",
    "        \n",
    "        acc, rk = evaluate_acc_rk(model, dataloader, device)\n",
    "        print(f'Model: {model_name} - Dataset: {data_name} - Accuracy: {acc*100:>3f}%, RK: {rk:>3f}')\n",
    "\n",
    "# free up some RAM\n",
    "del stress_tests_datasets\n",
    "del data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b965daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2607049bbb217602c768d881bc2d2ac1a9d805d61b88dee402243609ae704af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
