{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aca2c3f",
   "metadata": {},
   "source": [
    "# Objective: Fine-tune GPT-2 with the resulting filtered dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b36a91",
   "metadata": {},
   "source": [
    "### 1. Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941af00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, disable_caching\n",
    "from transformers import GPT2TokenizerFast, DataCollatorWithPadding, GPT2ForSequenceClassification, set_seed\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from utils_ import tokenize, train_classifier\n",
    "import pickle\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "set_seed(42)\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15b80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up tokeniser\n",
    "# padding to left because GPT2 uses last token for prediction\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\", padding_side = 'left', \\\n",
    "                                              padding = True, truncation = True)\n",
    "tokenizer.pad_token = tokenizer.eos_token # pad with 'eos' token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "393cf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data collator - https://huggingface.co/docs/transformers/main_classes/data_collator\n",
    "# this is a (callable) helper object that sends batches of data to the model\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding = 'max_length', \\\n",
    "                                         return_tensors = 'pt', max_length = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d163a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in indices removed by AFLite for each seed\n",
    "with open('removed_idx.pkl', 'rb') as f:\n",
    "    removed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd01aee8",
   "metadata": {},
   "source": [
    "## 2. Pre-processing Routine for SNLI\n",
    "- Get SNLI Dataset (Train fold) and shuffle it using the same seed as used for obtaining GPT-2 based Feature Representation (see notebook [Filtering_Part1.ipynb](https://github.com/shashiniyer/adversarial_nli_gpt2/blob/main/gpt2-small/notebooks_and_scripts/Filtering_Part1.ipynb))\n",
    "- Remove instances without gold standard labels, i.e., label = -1\n",
    "- One-hot encoding for labels\n",
    "- Partition data 10%/90%; use the 90% as unfiltered `train`\n",
    "- Filter out what AFLite run removed (see notebook [Filtering_Part2.ipynb](https://github.com/shashiniyer/adversarial_nli_gpt2/blob/main/gpt2-small/notebooks_and_scripts/Filtering_Part2.ipynb))\n",
    "- Tokenise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1f79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_snli(seed):\n",
    "    \n",
    "    # set up `train` dataset\n",
    "    snli_train = load_dataset('snli', split = 'train').shuffle(seed = 42)\n",
    "    snli_train = snli_train.filter(lambda x: x['label'] != -1).map( \\\n",
    "        lambda x: {'label': one_hot(torch.tensor(x['label']), 3).type(torch.float32).numpy()}, \\\n",
    "        batched = True)\n",
    "    train = snli_train.select(range(int(len(snli_train)/10), len(snli_train)))\n",
    "    \n",
    "    # filter out what AFLite run removed\n",
    "    removed_idx = [int(x) for x in removed[seed].split(',')[1:]] \n",
    "    train = train.select(set(range(len(train))) - set(removed_idx))\n",
    "    \n",
    "    # tokenize data\n",
    "    train = train.map(lambda x: tokenize(tokenizer, x['premise'] + '|' + x['hypothesis']))\n",
    "    len_bef_exclusion = len(train)\n",
    "\n",
    "    # exclude instances with > 128 tokens\n",
    "    train = train.filter(lambda x: x['exclude'] == False)\n",
    "    len_aft_exclusion = len(train)\n",
    "\n",
    "    # print message if instances were in fact excluded\n",
    "    if len_bef_exclusion - len_aft_exclusion > 0:\n",
    "\n",
    "        print(f'{len_bef_exclusion - len_aft_exclusion} ' + \\\n",
    "              f'({(len_bef_exclusion/len_aft_exclusion - 1)*100:>2f}%) sequences excluded')\n",
    "\n",
    "    # keep only needed columns, set data format to PyTorch\n",
    "    train.set_format(type = 'torch', columns = ['label', 'input_ids', 'attention_mask'])\n",
    "\n",
    "    return(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06ac3bd",
   "metadata": {},
   "source": [
    "### 3. Run fine-tuning step and save resulting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc649eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0 begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/shana92/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9642bdd3fbbb46ccb5aeb9a7cf387062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/551 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c89734fc8d4c48ab47dac23b01f1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c92fa08d4314c949d6add89826be3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/262396 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd4e092b1244119a16e90d67ddfc047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data Read In\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e54fea6f914ed8955727a9a12e4d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.757688  [    0/262396]\n",
      "loss: 0.639000  [26240/262396]\n",
      "loss: 0.604016  [52480/262396]\n",
      "loss: 0.598526  [78720/262396]\n",
      "loss: 0.604191  [104960/262396]\n",
      "loss: 0.579932  [131200/262396]\n",
      "loss: 0.542527  [157440/262396]\n",
      "loss: 0.543326  [183680/262396]\n",
      "loss: 0.473438  [209920/262396]\n",
      "loss: 0.464315  [236160/262396]\n",
      "Epoch average loss: 0.5419945120811462\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2184d18fe9cc4be79e0cdffea9b64f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.427399  [    0/262396]\n",
      "loss: 0.435798  [26240/262396]\n",
      "loss: 0.367921  [52480/262396]\n",
      "loss: 0.435413  [78720/262396]\n",
      "loss: 0.441651  [104960/262396]\n",
      "loss: 0.429242  [131200/262396]\n",
      "loss: 0.329641  [157440/262396]\n",
      "loss: 0.403802  [183680/262396]\n",
      "loss: 0.369968  [209920/262396]\n",
      "loss: 0.447986  [236160/262396]\n",
      "Epoch average loss: 0.39370766282081604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96d6f45d19e4d3ebba8889804b1ea8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.384310  [    0/262396]\n",
      "loss: 0.349832  [26240/262396]\n",
      "loss: 0.259876  [52480/262396]\n",
      "loss: 0.349334  [78720/262396]\n",
      "loss: 0.342495  [104960/262396]\n",
      "loss: 0.305910  [131200/262396]\n",
      "loss: 0.260810  [157440/262396]\n",
      "loss: 0.334609  [183680/262396]\n",
      "loss: 0.311066  [209920/262396]\n",
      "loss: 0.316424  [236160/262396]\n",
      "Epoch average loss: 0.341413289308548\n",
      "Done!\n",
      "Seed 0 complete\n",
      "Seed 1 begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/shana92/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acb2f6d5a6b4f97895c80fb61bad504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/551 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6d6428eed64de6b4d4a1d0eaa1dd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687949e7c84a451bbc3e0960f845660d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/262079 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d842629743047e6ab233e7a9c5120b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data Read In\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63081475d7b4ab598212441335b853c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4095 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.939102  [    0/262079]\n",
      "loss: 0.650807  [26176/262079]\n",
      "loss: 0.637025  [52352/262079]\n",
      "loss: 0.572087  [78528/262079]\n",
      "loss: 0.463744  [104704/262079]\n",
      "loss: 0.473584  [130880/262079]\n",
      "loss: 0.484078  [157056/262079]\n",
      "loss: 0.526533  [183232/262079]\n",
      "loss: 0.444780  [209408/262079]\n",
      "loss: 0.527884  [235584/262079]\n",
      "loss: 0.406123  [261760/262079]\n",
      "Epoch average loss: 0.5199455618858337\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d707df613975404c8b81ff65ee945915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4095 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.499139  [    0/262079]\n",
      "loss: 0.459934  [26176/262079]\n",
      "loss: 0.376811  [52352/262079]\n",
      "loss: 0.307248  [78528/262079]\n",
      "loss: 0.328775  [104704/262079]\n",
      "loss: 0.423708  [130880/262079]\n",
      "loss: 0.375343  [157056/262079]\n",
      "loss: 0.366637  [183232/262079]\n",
      "loss: 0.400426  [209408/262079]\n",
      "loss: 0.312537  [235584/262079]\n",
      "loss: 0.321643  [261760/262079]\n",
      "Epoch average loss: 0.37954846024513245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006a692d034b4673902be4eb28487e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4095 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.400075  [    0/262079]\n",
      "loss: 0.369990  [26176/262079]\n",
      "loss: 0.393274  [52352/262079]\n",
      "loss: 0.304584  [78528/262079]\n",
      "loss: 0.413210  [104704/262079]\n",
      "loss: 0.334329  [130880/262079]\n",
      "loss: 0.273709  [157056/262079]\n",
      "loss: 0.366422  [183232/262079]\n",
      "loss: 0.397555  [209408/262079]\n",
      "loss: 0.340288  [235584/262079]\n",
      "loss: 0.259924  [261760/262079]\n",
      "Epoch average loss: 0.3353414237499237\n",
      "Done!\n",
      "Seed 1 complete\n",
      "Seed 2 begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/shana92/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af88d9a4c194d8b9a9bcaecf01839a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/551 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c920cce45c6e4ee1b53c7b74d6fdd846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f763aa924f45fc91b78b80c4e1c587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/262330 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa065be573e4c32a09742f64355e842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data Read In\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ba5ee8460f4c0e82ed0d090e951c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.861917  [    0/262330]\n",
      "loss: 0.634136  [26176/262330]\n",
      "loss: 0.630388  [52352/262330]\n",
      "loss: 0.548637  [78528/262330]\n",
      "loss: 0.526299  [104704/262330]\n",
      "loss: 0.506436  [130880/262330]\n",
      "loss: 0.492384  [157056/262330]\n",
      "loss: 0.491082  [183232/262330]\n",
      "loss: 0.482625  [209408/262330]\n",
      "loss: 0.463158  [235584/262330]\n",
      "loss: 0.449278  [261760/262330]\n",
      "Epoch average loss: 0.5308033227920532\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca7a9a9f72347d699f3084bf667231a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.323597  [    0/262330]\n",
      "loss: 0.441712  [26176/262330]\n",
      "loss: 0.379708  [52352/262330]\n",
      "loss: 0.404740  [78528/262330]\n",
      "loss: 0.389663  [104704/262330]\n",
      "loss: 0.398999  [130880/262330]\n",
      "loss: 0.351477  [157056/262330]\n",
      "loss: 0.333535  [183232/262330]\n",
      "loss: 0.309637  [209408/262330]\n",
      "loss: 0.405708  [235584/262330]\n",
      "loss: 0.371995  [261760/262330]\n",
      "Epoch average loss: 0.38767144083976746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e05eef2a6ce4c2c9f9636d67725f102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.411243  [    0/262330]\n",
      "loss: 0.455609  [26176/262330]\n",
      "loss: 0.262094  [52352/262330]\n",
      "loss: 0.353340  [78528/262330]\n",
      "loss: 0.261723  [104704/262330]\n",
      "loss: 0.256272  [130880/262330]\n",
      "loss: 0.254492  [157056/262330]\n",
      "loss: 0.303975  [183232/262330]\n",
      "loss: 0.328739  [209408/262330]\n",
      "loss: 0.284473  [235584/262330]\n",
      "loss: 0.280484  [261760/262330]\n",
      "Epoch average loss: 0.3402520418167114\n",
      "Done!\n",
      "Seed 2 complete\n",
      "Seed 3 begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/shana92/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3163afc283d412e96d38bb06f0b697e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/551 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1613504198d4aa7b4cadca4726a5544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2596c9a463e48e79645ab630bb0a863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256809 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d684e49279eb4de58aa4ffeea26ca9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/257 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data Read In\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f90c05643fc4f1fa67a784cdc6658fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4013 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.796898  [    0/256809]\n",
      "loss: 0.626781  [25664/256809]\n",
      "loss: 0.649242  [51328/256809]\n",
      "loss: 0.561202  [76992/256809]\n",
      "loss: 0.579713  [102656/256809]\n",
      "loss: 0.528545  [128320/256809]\n",
      "loss: 0.484664  [153984/256809]\n",
      "loss: 0.541037  [179648/256809]\n",
      "loss: 0.485742  [205312/256809]\n",
      "loss: 0.453123  [230976/256809]\n",
      "loss: 0.394164  [256640/256809]\n",
      "Epoch average loss: 0.54237300157547\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414e0ea3f94440e8badb5eb07d58f7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4013 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.413500  [    0/256809]\n",
      "loss: 0.423586  [25664/256809]\n",
      "loss: 0.425314  [51328/256809]\n",
      "loss: 0.379643  [76992/256809]\n",
      "loss: 0.422790  [102656/256809]\n",
      "loss: 0.446650  [128320/256809]\n",
      "loss: 0.335778  [153984/256809]\n",
      "loss: 0.360096  [179648/256809]\n",
      "loss: 0.405407  [205312/256809]\n",
      "loss: 0.263682  [230976/256809]\n",
      "loss: 0.362599  [256640/256809]\n",
      "Epoch average loss: 0.38935941457748413\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7a6f1142564f9892b9bd15dcadc5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4013 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.334590  [    0/256809]\n",
      "loss: 0.354069  [25664/256809]\n",
      "loss: 0.356162  [51328/256809]\n",
      "loss: 0.228001  [76992/256809]\n",
      "loss: 0.287348  [102656/256809]\n",
      "loss: 0.419076  [128320/256809]\n",
      "loss: 0.260109  [153984/256809]\n",
      "loss: 0.310465  [179648/256809]\n",
      "loss: 0.277157  [205312/256809]\n",
      "loss: 0.388664  [230976/256809]\n",
      "loss: 0.246732  [256640/256809]\n",
      "Epoch average loss: 0.33925527334213257\n",
      "Done!\n",
      "Seed 3 complete\n",
      "Seed 4 begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/shana92/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555b10b3ce9f40478efe51041dce7fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/551 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2f2f9718b24095b7bf623fe4ac0fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ef315d08344f8c95d584f28f7ef5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265398 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e2d14fb4094fbea965ac96634bc27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data Read In\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8d2b27270745f2aadc4c448fd27283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.528919  [    0/265398]\n",
      "loss: 0.629002  [26496/265398]\n",
      "loss: 0.644122  [52992/265398]\n",
      "loss: 0.521323  [79488/265398]\n",
      "loss: 0.615192  [105984/265398]\n",
      "loss: 0.603087  [132480/265398]\n",
      "loss: 0.637906  [158976/265398]\n",
      "loss: 0.478359  [185472/265398]\n",
      "loss: 0.548402  [211968/265398]\n",
      "loss: 0.481871  [238464/265398]\n",
      "loss: 0.448869  [264960/265398]\n",
      "Epoch average loss: 0.5331658720970154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba090ab295b49229a23679e743b3a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.430480  [    0/265398]\n",
      "loss: 0.381909  [26496/265398]\n",
      "loss: 0.373069  [52992/265398]\n",
      "loss: 0.370104  [79488/265398]\n",
      "loss: 0.423201  [105984/265398]\n",
      "loss: 0.445478  [132480/265398]\n",
      "loss: 0.397075  [158976/265398]\n",
      "loss: 0.329071  [185472/265398]\n",
      "loss: 0.320523  [211968/265398]\n",
      "loss: 0.317310  [238464/265398]\n",
      "loss: 0.354632  [264960/265398]\n",
      "Epoch average loss: 0.38367968797683716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc1f0ce5d2941e48edb15a62aff7f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.354580  [    0/265398]\n",
      "loss: 0.364377  [26496/265398]\n",
      "loss: 0.302272  [52992/265398]\n",
      "loss: 0.432563  [79488/265398]\n",
      "loss: 0.349704  [105984/265398]\n",
      "loss: 0.283945  [132480/265398]\n",
      "loss: 0.290156  [158976/265398]\n",
      "loss: 0.301987  [185472/265398]\n",
      "loss: 0.365680  [211968/265398]\n",
      "loss: 0.317792  [238464/265398]\n",
      "loss: 0.377326  [264960/265398]\n",
      "Epoch average loss: 0.3356095552444458\n",
      "Done!\n",
      "Seed 4 complete\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters for model training\n",
    "batch_size = 64 # constrained by GPU memory\n",
    "lr = 1e-5 # set to match Le et al. (2020) - https://arxiv.org/abs/2002.04108\n",
    "\n",
    "# from Filtering_Part2.ipynb\n",
    "AFLite_seeds = [0, 1, 2, 3, 4]\n",
    "    \n",
    "# Begin fine-tuning\n",
    "for seed in AFLite_seeds:\n",
    "    \n",
    "    # print log message\n",
    "    print(f'Seed {seed} begin')\n",
    "    \n",
    "    # read in filtered data\n",
    "    data = preprocess_snli(seed)\n",
    "    print('Filtered Data Read In')\n",
    "    \n",
    "    # instantiate new GPT-2 based model\n",
    "    model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", \n",
    "                                      num_labels=3,\n",
    "                                      problem_type=\"multi_label_classification\")\n",
    "    model.config.pad_token_id = model.config.eos_token_id # specify pad_token used by tokenizer\n",
    "    \n",
    "    # set up data loader\n",
    "    dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, \\\n",
    "                                             shuffle=True, collate_fn=data_collator)\n",
    "    \n",
    "    # set up optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)    \n",
    "    \n",
    "    # fine-tune model\n",
    "    torch.save(train_classifier(model, dataloader, optimizer, device), \\\n",
    "              'AFLite_fine_tuned_model_seed' + str(seed) + '.pth')\n",
    "    \n",
    "    # print log message\n",
    "    print(f'Seed {seed} complete')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df423765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
